{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MET CS677 Data Science with Python - Assignment 2\n",
    "### Alan Szmyt\n",
    "#### Built with Python 3.10.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:29:58.065314Z",
     "start_time": "2023-03-29T16:29:57.953419Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.6\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:29:58.127006Z",
     "start_time": "2023-03-29T16:29:58.031962Z"
    }
   },
   "outputs": [],
   "source": [
    "# This enables SVG graphics inline (only use with static plots (non-Bokeh))\n",
    "%config InlineBackend.figure_formats = {'svg',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:29:58.127953Z",
     "start_time": "2023-03-29T16:29:58.042612Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "MathJax.Hub.Config({\n",
       "    tex2jax: {\n",
       "        inlineMath: [['$','$'], ['\\\\(','\\\\)']],\n",
       "        processEscapes: true\n",
       "    },\n",
       "    tex: {\n",
       "        packages: {'[+]': ['require']},\n",
       "    },\n",
       "});\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "MathJax.Hub.Config({\n",
    "    tex2jax: {\n",
    "        inlineMath: [['$','$'], ['\\\\(','\\\\)']],\n",
    "        processEscapes: true\n",
    "    },\n",
    "    tex: {\n",
    "        packages: {'[+]': ['require']},\n",
    "    },\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:29:58.875212Z",
     "start_time": "2023-03-29T16:29:58.046823Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resources directory is located at /home/alan/src/bu/cs677/assignment2/assignment2/resources.\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from assignment2 import (\n",
    "    add_true_labels,\n",
    "    buy_and_hold,\n",
    "    buy_from_prediction,\n",
    "    get_labels,\n",
    "    linechart,\n",
    "    get_both_up_days,\n",
    "    get_training_tables,\n",
    "    get_testing_tables,\n",
    "    get_years,\n",
    "    get_statistics,\n",
    "    float_to_percentage,\n",
    "    predict_next_day,\n",
    "    w_prediction_accuracy,\n",
    "    question_1_3,\n",
    "    question_1_4,\n",
    "    read_stocks,\n",
    "    prediction_accuracy,\n",
    "    show_table,\n",
    "    show_tables,\n",
    "    compute_ensemble,\n",
    "    style_df,\n",
    ")\n",
    "from constants import (\n",
    "    SONY_TICKER,\n",
    "    SPY_TICKER,\n",
    "    DATE_KEY,\n",
    "    TRUE_LABEL_KEY,\n",
    "    ENSEMBLE_ORACLE_KEY,\n",
    "    W_ORACLE,\n",
    "    BUY_AND_HOLD_KEY,\n",
    "    ENSEMBLE_KEY\n",
    ")\n",
    "from utils import (\n",
    "    compute_probability,\n",
    "    mean,\n",
    "    resources,\n",
    ")\n",
    "from typing import cast\n",
    "from pandas import DataFrame, Series\n",
    "from IPython.display import Latex\n",
    "from pandas.io.formats.style import Styler\n",
    "from pandas._config import config # noqa\n",
    "from pandas._config.config import is_bool, OptionError # noqa\n",
    "\n",
    "# Global pandas options.\n",
    "pd.set_option('display.max_rows', 10)\n",
    "\n",
    "# TODO Don't have time.\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "# Columns to drop for visual export.\n",
    "drop_cols = [\n",
    "    \"Week_Number\",\n",
    "    \"Year_Week\",\n",
    "    \"Short_MA\",\n",
    "    \"Long_MA\",\n",
    "    \"Adj Close\",\n",
    "]\n",
    "\n",
    "print(f\"Resources directory is located at {resources}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:29:58.959845Z",
     "start_time": "2023-03-29T16:29:58.878711Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read the stock data files into pandas dataframes.\n",
    "sony_dataframe, spy_dataframe = cast(tuple[DataFrame, DataFrame], read_stocks())\n",
    "\n",
    "sony_dataframe = sony_dataframe.drop(columns=drop_cols)\n",
    "spy_dataframe = spy_dataframe.drop(columns=drop_cols)\n",
    "\n",
    "# Set the date column to be datetime objects instead of string.\n",
    "sony_dataframe[DATE_KEY] = pd.to_datetime(sony_dataframe[DATE_KEY])\n",
    "spy_dataframe[DATE_KEY] = pd.to_datetime(spy_dataframe[DATE_KEY])\n",
    "\n",
    "# Create pandas stylers for each data set.\n",
    "sony_table: Styler = style_df(data=sony_dataframe, caption=\"SONY Stock Dataset\", color=False)\n",
    "spy_table: Styler = style_df(data=spy_dataframe, caption=\"S&P-500 Stock Dataset\", color=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:29:58.968174Z",
     "start_time": "2023-03-29T16:29:58.954371Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "In many data science applications, you want to identify patterns, labels or classes based on available data. In this assignment we will focus on discovering patterns in your past stock behavior.\n",
       "To each trading day $i$ you will assign a \"trading\" label \"+\" or \"-\" depending whether the corresponding daily return for that day $r_i \\ge{0}$ or $r_i <{0}$. We will call these \"true\" labels and we compute these for all days in all 5 years.\n",
       "We will use years 1, 2, and 3 as training years and we will use years 4 and 5 as testing years. For each day in years 4 and 5, we will predict a label based on some patterns that we observe in training years. We will call these \"predicted\" labels. We know the \"true\" labels for years 4 and 5 and we compute \"predicted\" labels for years 4 and 5. Therefore, we can analyze how good are our predictions for all labels, \"+\" labels only and \"-\" labels only in years 4 and 5."
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assignment description.\n",
    "Latex(\n",
    "    r'In many data science applications, you want to identify patterns, labels or classes based on available data. In this assignment we will focus on discovering patterns in your past stock behavior.'\n",
    "    \"\\n\"\n",
    "    r'To each trading day $i$ you will assign a \"trading\" label \"+\" or \"-\" depending whether the corresponding daily return for that day $r_i \\ge{0}$ or $r_i <{0}$. We will call these \"true\" labels and we compute these for all days in all 5 years.'\n",
    "    \"\\n\"\n",
    "    r'We will use years 1, 2, and 3 as training years and we will use years 4 and 5 as testing years. For each day in years 4 and 5, we will predict a label based on some patterns that we observe in training years. We will call these \"predicted\" labels. We know the \"true\" labels for years 4 and 5 and we compute \"predicted\" labels for years 4 and 5. Therefore, we can analyze how good are our predictions for all labels, \"+\" labels only and \"-\" labels only in years 4 and 5.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:29:59.074644Z",
     "start_time": "2023-03-29T16:29:58.961207Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\textbf{Question 1: }$ You have a csv table of daily returns for your stock and for S\\&P-500 (\"SPY\" ticker)."
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Latex(r'$\\textbf{Question 1: }$ You have a csv table of daily returns for your stock and for S\\&P-500 (\"SPY\" ticker).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:29:59.192368Z",
     "start_time": "2023-03-29T16:29:58.962998Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\\begin{tabular}{lrrrlrr}\n",
       " & Year & Month & Day & Weekday & Volume & Return \\\\\n",
       "0 & 2016 & 1 & 4 & Monday & 2482200 & 0.000000 \\\\\n",
       "1 & 2016 & 1 & 5 & Tuesday & 3482600 & 0.029923 \\\\\n",
       "2 & 2016 & 1 & 6 & Wednesday & 5280900 & -0.072242 \\\\\n",
       "3 & 2016 & 1 & 7 & Thursday & 2109400 & -0.015235 \\\\\n",
       "4 & 2016 & 1 & 8 & Friday & 1869600 & -0.011603 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\\begin{tabular}{lrrrlrr}\n",
       " & Year & Month & Day & Weekday & Volume & Return \\\\\n",
       "0 & 2016 & 1 & 4 & Monday & 222353500 & 0.000000 \\\\\n",
       "1 & 2016 & 1 & 5 & Tuesday & 110845800 & 0.001691 \\\\\n",
       "2 & 2016 & 1 & 6 & Wednesday & 152112600 & -0.012614 \\\\\n",
       "3 & 2016 & 1 & 7 & Thursday & 213436100 & -0.023992 \\\\\n",
       "4 & 2016 & 1 & 8 & Friday & 209817200 & -0.010976 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display tables with the original csv datasets.\n",
    "show_tables([sony_table, spy_table])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:29:59.192943Z",
     "start_time": "2023-03-29T16:29:59.137079Z"
    }
   },
   "outputs": [],
   "source": [
    "table_1: Styler = style_df(\n",
    "    data=DataFrame(\n",
    "        {\n",
    "            \"Date\": [\"1/2/2015\", \"1/3/2015\", \"1/6/2015\", \". . .\", \". . .\", \"12/30/2019\", \"12/31/2019\"],\n",
    "            \". . .\": [\". . .\", \". . .\", \". . .\", \". . .\", \". . .\", \". . .\", \". . .\"],\n",
    "            \"Return\": [\"0.015\", \"-0.01\", \"0.0.2\", \". . .\", \". . .\", \"0\", \"-0.03\"]\n",
    "        }\n",
    "    ),\n",
    "    caption=\"Table 1: Initial data\",\n",
    "    color=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:29:59.193622Z",
     "start_time": "2023-03-29T16:29:59.137563Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       " 1. For each file, read them into a pandas frame and add a column \"True Label\". In that column, for each day (row) $i$ with daily return $r_i \\ge{0}$ you assign a \"+\" label (\"up day\"). For each day $i$ with daily return $r_i <{0}$ you assign \"-\" (\"down days\"). You do this for every day for all 5 years for both tickers.\n",
       "For example, if your initial dataframe were:"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Open', 'Close', 'High', 'Low'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 8\u001B[0m\n\u001B[1;32m      1\u001B[0m display(\n\u001B[1;32m      2\u001B[0m     Latex(\n\u001B[1;32m      3\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m 1. For each file, read them into a pandas frame and add a column \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTrue Label\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m. In that column, for each day (row) $i$ with daily return $r_i \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mge\u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m$ you assign a \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m+\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m label (\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mup day\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m). For each day $i$ with daily return $r_i <\u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m$ you assign \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m (\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdown days\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m). You do this for every day for all 5 years for both tickers.\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m      6\u001B[0m     )\n\u001B[1;32m      7\u001B[0m )\n\u001B[0;32m----> 8\u001B[0m \u001B[43mshow_table\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtable_1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_rows\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m Latex(\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124myou will add an additional column \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTrue Label\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m and have data as shown in Table 2.\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mYour daily \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrue labels\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m sequence is $+,-,+,...,+,-$.\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     13\u001B[0m )\n",
      "File \u001B[0;32m~/src/bu/cs677/assignment2/assignment2/assignment2.py:121\u001B[0m, in \u001B[0;36mshow_table\u001B[0;34m(table, max_rows)\u001B[0m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m should_show_tables:\n\u001B[1;32m    119\u001B[0m     table_to_show: Styler \u001B[38;5;241m=\u001B[39m table \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(table, Styler) \u001B[38;5;28;01melse\u001B[39;00m table\u001B[38;5;241m.\u001B[39mstyle\n\u001B[0;32m--> 121\u001B[0m     display(Markdown(\u001B[43mtable_to_show\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mOpen\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mDate\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mClose\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mHigh\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mLow\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mhead(max_rows)\u001B[38;5;241m.\u001B[39mstyle\u001B[38;5;241m.\u001B[39mto_latex()))\n",
      "File \u001B[0;32m~/src/bu/cs677/assignment2/.venv/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[1;32m    326\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    327\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39m_format_argument_list(allow_args)),\n\u001B[1;32m    328\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[1;32m    329\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mfind_stack_level(),\n\u001B[1;32m    330\u001B[0m     )\n\u001B[0;32m--> 331\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/src/bu/cs677/assignment2/.venv/lib/python3.10/site-packages/pandas/core/frame.py:5399\u001B[0m, in \u001B[0;36mDataFrame.drop\u001B[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001B[0m\n\u001B[1;32m   5251\u001B[0m \u001B[38;5;129m@deprecate_nonkeyword_arguments\u001B[39m(version\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, allowed_args\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mself\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m   5252\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdrop\u001B[39m(  \u001B[38;5;66;03m# type: ignore[override]\u001B[39;00m\n\u001B[1;32m   5253\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   5260\u001B[0m     errors: IgnoreRaise \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   5261\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   5262\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   5263\u001B[0m \u001B[38;5;124;03m    Drop specified labels from rows or columns.\u001B[39;00m\n\u001B[1;32m   5264\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   5397\u001B[0m \u001B[38;5;124;03m            weight  1.0     0.8\u001B[39;00m\n\u001B[1;32m   5398\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 5399\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   5400\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5401\u001B[0m \u001B[43m        \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5402\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5403\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5404\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5405\u001B[0m \u001B[43m        \u001B[49m\u001B[43minplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minplace\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5406\u001B[0m \u001B[43m        \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5407\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/src/bu/cs677/assignment2/.venv/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[1;32m    326\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    327\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39m_format_argument_list(allow_args)),\n\u001B[1;32m    328\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[1;32m    329\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mfind_stack_level(),\n\u001B[1;32m    330\u001B[0m     )\n\u001B[0;32m--> 331\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/src/bu/cs677/assignment2/.venv/lib/python3.10/site-packages/pandas/core/generic.py:4505\u001B[0m, in \u001B[0;36mNDFrame.drop\u001B[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001B[0m\n\u001B[1;32m   4503\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m axis, labels \u001B[38;5;129;01min\u001B[39;00m axes\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m   4504\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m labels \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 4505\u001B[0m         obj \u001B[38;5;241m=\u001B[39m \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_drop_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4507\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m inplace:\n\u001B[1;32m   4508\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_inplace(obj)\n",
      "File \u001B[0;32m~/src/bu/cs677/assignment2/.venv/lib/python3.10/site-packages/pandas/core/generic.py:4546\u001B[0m, in \u001B[0;36mNDFrame._drop_axis\u001B[0;34m(self, labels, axis, level, errors, only_slice)\u001B[0m\n\u001B[1;32m   4544\u001B[0m         new_axis \u001B[38;5;241m=\u001B[39m axis\u001B[38;5;241m.\u001B[39mdrop(labels, level\u001B[38;5;241m=\u001B[39mlevel, errors\u001B[38;5;241m=\u001B[39merrors)\n\u001B[1;32m   4545\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 4546\u001B[0m         new_axis \u001B[38;5;241m=\u001B[39m \u001B[43maxis\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4547\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m axis\u001B[38;5;241m.\u001B[39mget_indexer(new_axis)\n\u001B[1;32m   4549\u001B[0m \u001B[38;5;66;03m# Case for non-unique axis\u001B[39;00m\n\u001B[1;32m   4550\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/src/bu/cs677/assignment2/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:6934\u001B[0m, in \u001B[0;36mIndex.drop\u001B[0;34m(self, labels, errors)\u001B[0m\n\u001B[1;32m   6932\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mask\u001B[38;5;241m.\u001B[39many():\n\u001B[1;32m   6933\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m errors \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m-> 6934\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlist\u001B[39m(labels[mask])\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not found in axis\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   6935\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m indexer[\u001B[38;5;241m~\u001B[39mmask]\n\u001B[1;32m   6936\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdelete(indexer)\n",
      "\u001B[0;31mKeyError\u001B[0m: \"['Open', 'Close', 'High', 'Low'] not found in axis\""
     ]
    }
   ],
   "source": [
    "display(\n",
    "    Latex(\n",
    "        r' 1. For each file, read them into a pandas frame and add a column \"True Label\". In that column, for each day (row) $i$ with daily return $r_i \\ge{0}$ you assign a \"+\" label (\"up day\"). For each day $i$ with daily return $r_i <{0}$ you assign \"-\" (\"down days\"). You do this for every day for all 5 years for both tickers.'\n",
    "        \"\\n\"\n",
    "        r'For example, if your initial dataframe were:'\n",
    "    )\n",
    ")\n",
    "show_table(table_1, max_rows=10)\n",
    "Latex(\n",
    "    r'you will add an additional column \"True Label\" and have data as shown in Table 2.'\n",
    "    \"\\n\"\n",
    "    r'Your daily \"true labels\" sequence is $+,-,+,...,+,-$.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:29:59.194076Z",
     "start_time": "2023-03-29T16:29:59.137919Z"
    }
   },
   "outputs": [],
   "source": [
    "table_2: DataFrame = table_1.data.copy()\n",
    "table_2[TRUE_LABEL_KEY] = [\"+\", \"-\", \"+\", \". . .\", \". . .\", \"+\", \"-\"]\n",
    "table_2: Styler = Styler(data=table_2, caption=\"Table 2: Adding True Labels\")\n",
    "show_table(table_2, max_rows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:29:59.314425Z",
     "start_time": "2023-03-29T16:29:59.138237Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add 'True Label' column based upon the daily return.\n",
    "add_true_labels(sony_dataframe)\n",
    "add_true_labels(spy_dataframe)\n",
    "\n",
    "# Display the updated tables with the styled 'True Labels' column.\n",
    "show_tables([sony_table, spy_table])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:29:59.314721Z",
     "start_time": "2023-03-29T16:29:59.260981Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Get a list of all the years in the dataset.\n",
    "sony_years, spy_years = cast(\n",
    "    tuple[list[int], list[int]], get_years(sony_dataframe, spy_dataframe)\n",
    ")\n",
    "\n",
    "# Separate data into training and testing data based upon the years.\n",
    "# Create training dataset from years 1, 2, and 3.\n",
    "sony_training_table, spy_training_table = cast(\n",
    "    tuple[DataFrame, DataFrame],\n",
    "    get_training_tables((sony_dataframe, sony_years), (spy_dataframe, spy_years)),\n",
    ")\n",
    "\n",
    "# Create testing dataset from years 4 and 5.\n",
    "sony_testing_table, spy_testing_table = cast(\n",
    "    tuple[DataFrame, DataFrame],\n",
    "    get_testing_tables((sony_dataframe, sony_years), (spy_dataframe, spy_years)),\n",
    ")\n",
    "\n",
    "# Get the 'up days' for the training datasets.\n",
    "sony_training_up_days, spy_training_up_days = cast(\n",
    "    tuple[DataFrame, DataFrame],\n",
    "    get_both_up_days(sony_training_table, spy_training_table),\n",
    ")\n",
    "\n",
    "# Get arrays of the training labels.\n",
    "sony_training_labels: np.ndarray = get_labels(sony_training_table)\n",
    "spy_training_labels: np.ndarray = get_labels(spy_training_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:29:59.345367Z",
     "start_time": "2023-03-29T16:29:59.275030Z"
    }
   },
   "outputs": [],
   "source": [
    "Latex(\n",
    "    r' 2. Take years 1, 2, and 3. Let $L$ be the number of trading days. Assuming 250 trading days per year, $L$ will contain about 750 days. Let $L^-$ be all trading days with \"-\" labels and let $L^+$ be all trading days with \"+\" labels. Assuming that all days are independent of each other and that the ration of \"up\" and \"down\" days remains the same in the future, compute the default probability $p^*$ that the next day is a \"up\" day.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:29:59.345693Z",
     "start_time": "2023-03-29T16:29:59.281167Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute the default probability that the next day is an 'up' day.\n",
    "sony_default_probability: float = compute_probability(\n",
    "    len(sony_training_up_days), len(sony_training_table)\n",
    ")\n",
    "\n",
    "spy_default_probability: float = compute_probability(\n",
    "    len(spy_training_up_days), len(spy_training_table)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:29:59.345839Z",
     "start_time": "2023-03-29T16:29:59.324962Z"
    }
   },
   "outputs": [],
   "source": [
    "Latex(\n",
    "    r' 3. Take years 1, 2, and 3. What is the probability that after seeing $k$ consecutive \"down days\", the next day is an \"up day\"? For example, if $k = 3$, what is the probability of seeing \"$-,-,-,+$\" as opposed to seeing \"$-,-,-,-$\". Compute this for $k = 1,2,3$.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:29:59.346270Z",
     "start_time": "2023-03-29T16:29:59.325265Z"
    }
   },
   "outputs": [],
   "source": [
    "# k values for questions 1.3 and question 1.4.\n",
    "k_list: list[int] = [1, 2, 3]\n",
    "\n",
    "print(\"Question 1.3 with SONY dataset:\")\n",
    "question_1_3(k_list, sony_training_labels)\n",
    "\n",
    "print(\"Question 1.3 with S&P-500 dataset:\")\n",
    "question_1_3(k_list, spy_training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:29:59.346541Z",
     "start_time": "2023-03-29T16:29:59.325397Z"
    }
   },
   "outputs": [],
   "source": [
    "Latex(\n",
    "    r' 4. Take years 1, 2, and 3. What is the probability that after seeing $k$ consecutive \"up days\", the next day is still an \"up day\"? For example, if $k = 3$, what is the probability of seeing \"$+,+,+,+$\" as opposed to seeing \"$+,+,+,-$\"? Compute this for $k = 1,2,3$.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:29:59.400857Z",
     "start_time": "2023-03-29T16:29:59.325520Z"
    }
   },
   "outputs": [],
   "source": [
    "# Question 1.4 results for each dataset.\n",
    "print(\"Question 1.4 with SONY dataset:\")\n",
    "question_1_4(k_list, sony_training_labels)\n",
    "\n",
    "print(\"Question 1.4 with S&P-500 dataset:\")\n",
    "question_1_4(k_list, spy_training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:29:59.401246Z",
     "start_time": "2023-03-29T16:29:59.368916Z"
    }
   },
   "outputs": [],
   "source": [
    "Latex(\n",
    "    r'$\\textbf{Predicting Labels: }$    We will now describe a procedure to predict labels for each day in years 4 and 5 from the \"true\" labels in training years 1, 2, and 3.'\n",
    "    \"\\n\"\n",
    "    r'For each day $d$ in year 4 and 5, we look at the pattern of last $W$ true labels (including this day $d$). By looking at the frequency of this pattern and the true label for the next day in the training set, we will predict label for $d + 1$. Here $W$ is the $\\textbf{hyperparameter}$ that we will choose based upon our prediction accuracy.'\n",
    "    \"\\n\"\n",
    "    r'Suppose $W = 3$. You look at a particular day $d$ and suppose that the sequence of last $W$ labels is $s = \"-,+,-\"$. We want to predict the label for the next day $d + 1$. To do this, we count the number of sequences of length $W + 1$ in the training set where the first $W$ labels coincide with $s$. In other words, we count the number $N^-(s)$ of sequences \"$s,+$\". If $N^+(s) \\ge{N^-(s)}$, then the next day is assigned \"+\". If $N^+(s) < N^-(s)$, then the next day is assigned \"-\". In the unlikely event that $N^+(s) = N^-(s) = 0$, we will assign a label based upon the default probability $p*$ that we computed in the previous question.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:29:59.401500Z",
     "start_time": "2023-03-29T16:29:59.369067Z"
    }
   },
   "outputs": [],
   "source": [
    "Latex(r'$\\textbf{Question 2: }$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:29:59.401843Z",
     "start_time": "2023-03-29T16:29:59.369208Z"
    }
   },
   "outputs": [],
   "source": [
    "Latex(\n",
    "    r' 1. For $W = 2, 3, 4$, compute predicted labels for each day in year $4$ and $5$ based on true labels in years $1, 2$, and $3$ only'\n",
    "    \"\\n\"\n",
    "    r'Perform this for your ticker and for \"SPY\".'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:29:59.434496Z",
     "start_time": "2023-03-29T16:29:59.373077Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get arrays of the testing labels.\n",
    "sony_testing_labels: np.ndarray = get_labels(sony_testing_table)\n",
    "spy_testing_labels: np.ndarray = get_labels(spy_testing_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:30:13.951751Z",
     "start_time": "2023-03-29T16:29:59.377318Z"
    }
   },
   "outputs": [],
   "source": [
    "# W values for questions 2.\n",
    "w_list: list[int] = [2, 3, 4]\n",
    "\n",
    "# For W = 2, 3, 4: Predict the next day and add it to the testing table.\n",
    "for w in w_list:\n",
    "    # SONY dataset predictions.\n",
    "    sony_testing_table[f\"W{w}\"] = predict_next_day(\n",
    "        df=sony_testing_table,\n",
    "        training_labels=sony_testing_labels,\n",
    "        window_size=w,\n",
    "        default_probability=sony_default_probability,\n",
    "    )\n",
    "\n",
    "    # S&P-500 dataset predictions.\n",
    "    spy_testing_table[f\"W{w}\"] = predict_next_day(\n",
    "        df=spy_testing_table,\n",
    "        training_labels=spy_testing_labels,\n",
    "        window_size=w,\n",
    "        default_probability=spy_default_probability,\n",
    "    )\n",
    "\n",
    "show_tables([sony_testing_table, spy_testing_table])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:30:13.958452Z",
     "start_time": "2023-03-29T16:30:13.952083Z"
    }
   },
   "outputs": [],
   "source": [
    "Latex(\n",
    "    r' 2. For each $W = 2, 3, 4$, compute the accuracy - what percentage of true labels (both positive and negative) have you predicted correctly for the last two years.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:30:14.041201Z",
     "start_time": "2023-03-29T16:30:13.959294Z"
    }
   },
   "outputs": [],
   "source": [
    "w_accuracy_keys: list[str] = [f\"W{w}*\" for w in w_list]\n",
    "\n",
    "# Compute the prediction accuracy for SONY.\n",
    "w_prediction_accuracy(sony_testing_table, w_list)\n",
    "sony_accuracies = {key: sony_testing_table.attrs[key] for key in w_accuracy_keys}\n",
    "\n",
    "# Compute the prediction accuracy for S&P-500.\n",
    "w_prediction_accuracy(spy_testing_table, w_list)\n",
    "spy_accuracies = {key: spy_testing_table.attrs[key] for key in w_accuracy_keys}\n",
    "\n",
    "print(\"SONY prediction accuracies: \")\n",
    "for accuracy, value in sony_accuracies.items():\n",
    "    print(f\"{accuracy}: {value}\")\n",
    "\n",
    "print(\"S&P-500 prediction accuracies: \")\n",
    "for accuracy, value in spy_accuracies.items():\n",
    "    print(f\"{accuracy}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:30:14.042014Z",
     "start_time": "2023-03-29T16:30:13.999310Z"
    }
   },
   "outputs": [],
   "source": [
    "Latex(\n",
    "    r' 3. Which $W^*$ value gave you the highest accuracy for your stock and which $W^*$ value gave you the highest accuracy for S\\&P-500?'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:30:14.119680Z",
     "start_time": "2023-03-29T16:30:14.003667Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the highest accuracy value for SONY.\n",
    "sony_highest_accuracy: tuple[str, float] = \\\n",
    "    max(sony_accuracies.items(), key=operator.itemgetter(1))\n",
    "print(\n",
    "    f\"SONY highest accuracy is {sony_highest_accuracy[0]} with an accuracy of \"\n",
    "    f\"{sony_highest_accuracy[1]}.\"\n",
    ")\n",
    "\n",
    "# Get the highest accuracy value for S&P-500.\n",
    "spy_highest_accuracy: tuple[str, float] = \\\n",
    "    max(spy_accuracies.items(), key=operator.itemgetter(1))\n",
    "print(\n",
    "    f\"S&P-500 highest accuracy is {spy_highest_accuracy[0]} with an accuracy of \"\n",
    "    f\"{spy_highest_accuracy[1]}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:30:14.170970Z",
     "start_time": "2023-03-29T16:30:14.015980Z"
    }
   },
   "outputs": [],
   "source": [
    "Latex(\n",
    "    r'$\\textbf{Question 3: }$ One of the most powerful methods to (potentially) improve predictions is to combine predictions by some \"averaging\". This is called $\\textit{ensemble learning}$. Let us consider the following procedure: for every day $d$, you 3 predicted labels: for $W = 2$, $W = 3$, and $W = 4$. Let us compute an \"ensemble\" label for day $d$ by taking the majority of your labels for that day. For example, if your predicted labels were \"-\", \"-\", and \"+\", then we would take \"-\" as the ensemble label for day $d$ (the majority of the three labels is \"-\"). If, on the other hand, your predicted labels were \"-\", \"+\", and \"+\", then we would take \"+\" as the ensemble label for day $d$ (the majority of the predicted labels is \"+\"). Compute such ensemble labels and answer the following:'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:30:14.171327Z",
     "start_time": "2023-03-29T16:30:14.056751Z"
    }
   },
   "outputs": [],
   "source": [
    "Latex(\n",
    "    r' 1. Compute ensemble labels for year 4 and 5 for both your stock and S\\&P-500.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:30:14.525792Z",
     "start_time": "2023-03-29T16:30:14.056914Z"
    }
   },
   "outputs": [],
   "source": [
    "w_cols: list[str] = [\"W2\", \"W3\", \"W4\"]\n",
    "\n",
    "# Compute ensemble labels for year 4 and 5 of SONY.\n",
    "compute_ensemble(sony_testing_table, w_cols)\n",
    "sony_ensemble_row: Series = sony_testing_table[ENSEMBLE_KEY].transpose()\n",
    "print(sony_ensemble_row)\n",
    "\n",
    "# Compute ensemble labels for year 4 and 5 of S&P-500.\n",
    "compute_ensemble(spy_testing_table, w_cols)\n",
    "spy_ensemble_row: Series = spy_testing_table[ENSEMBLE_KEY].transpose()\n",
    "print(spy_ensemble_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:30:14.526989Z",
     "start_time": "2023-03-29T16:30:14.388701Z"
    }
   },
   "outputs": [],
   "source": [
    "Latex(\n",
    "    r' 2. For both S\\&P-500 and your ticker, what percentage of labels in year $4$ and $5$ do you compute correctly by using ensemble?'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:30:14.594981Z",
     "start_time": "2023-03-29T16:30:14.388910Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute ensemble labels for year 4 and 5 of S&P-500.\n",
    "compute_ensemble(spy_testing_table, w_cols)\n",
    "spy_ensemble_row: Series = spy_testing_table[ENSEMBLE_KEY].transpose()\n",
    "print(spy_ensemble_row)\n",
    "\n",
    "# Compute the accuracy of the ensemble column for SONY.\n",
    "prediction_accuracy(sony_testing_table, ENSEMBLE_KEY)\n",
    "sony_ensemble_accuracy: float = sony_testing_table.attrs[f'{ENSEMBLE_KEY}*']\n",
    "print(f\"Ensemble accuracy for SONY: {float_to_percentage(sony_ensemble_accuracy)}\")\n",
    "\n",
    "# Compute the accuracy of the ensemble column for S&P-500.\n",
    "prediction_accuracy(spy_testing_table, ENSEMBLE_KEY)\n",
    "spy_ensemble_accuracy: float = spy_testing_table.attrs[f'{ENSEMBLE_KEY}*']\n",
    "print(\n",
    "    f\"Ensemble accuracy for S&P-500: {float_to_percentage(spy_ensemble_accuracy)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:30:14.596081Z",
     "start_time": "2023-03-29T16:30:14.528580Z"
    }
   },
   "outputs": [],
   "source": [
    "Latex(\n",
    "    r' 3. Did you improve your accuracy on predicting \"-\" labels by using ensemble compared to $W = 2, 3, 4$?'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:30:14.596378Z",
     "start_time": "2023-03-29T16:30:14.576837Z"
    }
   },
   "outputs": [],
   "source": [
    "w_negative_keys: list[str] = [f\"W{w}-*\" for w in w_list]\n",
    "\n",
    "# Compute the prediction accuracy for negatives in SONY.\n",
    "w_prediction_accuracy(sony_testing_table, w_list, ('-',))\n",
    "sony_negative_accuracies = {\n",
    "    key: sony_testing_table.attrs[key] for key in w_negative_keys\n",
    "}\n",
    "prediction_accuracy(sony_testing_table, ENSEMBLE_KEY, ('-',))\n",
    "\n",
    "# Compare '-' accuracies.\n",
    "sony_ensemble_negative_accuracy: float = \\\n",
    "    sony_testing_table.attrs[f\"{ENSEMBLE_KEY}-*\"]\n",
    "sony_w_negative_accuracy: float = mean(list(sony_negative_accuracies.values()))\n",
    "\n",
    "print(f\"SONY Ensemble accuracy for '-': {sony_ensemble_negative_accuracy}\")\n",
    "print(f\"SONY W accuracy for '-': {sony_w_negative_accuracy}\")\n",
    "if sony_ensemble_negative_accuracy >= sony_w_negative_accuracy:\n",
    "    print(\"Ensemble for SONY had better accuracy than W for negative '-'.\")\n",
    "else:\n",
    "    print(\"W for SONY had better accuracy than Ensemble for negative '-'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:30:14.596613Z",
     "start_time": "2023-03-29T16:30:14.576976Z"
    }
   },
   "outputs": [],
   "source": [
    "Latex(\n",
    "    r' 4. Did you improve your accuracy on predicting \"+\" labels by using ensemble compared to $W = 2, 3, 4$?'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:30:14.805634Z",
     "start_time": "2023-03-29T16:30:14.577137Z"
    }
   },
   "outputs": [],
   "source": [
    "w_positive_keys: list[str] = [f\"W{w}+*\" for w in w_list]\n",
    "\n",
    "# Compute the prediction accuracy for positives in SONY.\n",
    "w_prediction_accuracy(sony_testing_table, w_list, ('+',))\n",
    "sony_positive_accuracies = {\n",
    "    key: sony_testing_table.attrs[key] for key in w_positive_keys\n",
    "}\n",
    "prediction_accuracy(sony_testing_table, ENSEMBLE_KEY, ('+',))\n",
    "\n",
    "# Compare '+' accuracies.\n",
    "sony_ensemble_positive_accuracy: float = \\\n",
    "    sony_testing_table.attrs[f\"{ENSEMBLE_KEY}+*\"]\n",
    "sony_w_positive_accuracy: float = mean(list(sony_positive_accuracies.values()))\n",
    "\n",
    "print(f\"SONY Ensemble accuracy for '+': {sony_ensemble_positive_accuracy}\")\n",
    "print(f\"SONY W accuracy for '+': {sony_w_positive_accuracy}\")\n",
    "if sony_ensemble_positive_accuracy >= sony_w_positive_accuracy:\n",
    "    print(\"Ensemble for SONY had better accuracy than W for positive '+'.\")\n",
    "else:\n",
    "    print(\"W for SONY had better accuracy than Ensemble for positive '+'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:30:14.806618Z",
     "start_time": "2023-03-29T16:30:14.620894Z"
    }
   },
   "outputs": [],
   "source": [
    "Latex(\n",
    "    r'$\\textbf{Question 4: }$ For $W = 2, 3, 4$ and ensemble, compute the following (both for your ticker and \"SPY\") statistics based upon years $4$ and $5$:'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:30:14.806951Z",
     "start_time": "2023-03-29T16:30:14.621043Z"
    }
   },
   "outputs": [],
   "source": [
    "Latex(\n",
    "    r' 1. TP - true positives (your predicted label is \"+\" and true label is \"+\".'\n",
    "    \"\\n\"\n",
    "    r' 2. FP - false positives (your predicted label is \"+\" but true label is \"-\".'\n",
    "    \"\\n\"\n",
    "    r' 3. TN - true negatives (your predicted label is \"-\" but true label is \"-\".'\n",
    "    \"\\n\"\n",
    "    r' 4. FN - false negatives (your predicted label is \"-\" but true label is \"+\".'\n",
    "    \"\\n\"\n",
    "    r' 5. TNR = TP/(TP + FN) - true positive rate. This is the fraction of positive labels that you predicted correctly. This is also called sensitivity, recall, or hit rate.'\n",
    "    \"\\n\"\n",
    "    r' 6. TNR = TN/(TN + FP) - true negative rate. This is the fraction of negative labels that you predicted correctly. This is also called specificity or selectivity.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:30:14.807204Z",
     "start_time": "2023-03-29T16:30:14.621169Z"
    }
   },
   "outputs": [],
   "source": [
    "Latex(\n",
    "    r' 7. Summarize your findings in the table below.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:30:14.810273Z",
     "start_time": "2023-03-29T16:30:14.634262Z"
    }
   },
   "outputs": [],
   "source": [
    "w_keys: list[str] = [\"W2\", \"W3\", \"W4\", ENSEMBLE_KEY]\n",
    "\n",
    "# Get statistics for all W labels in S&P-500 stock data table.\n",
    "spy_statistics_table: DataFrame = DataFrame([\n",
    "    get_statistics(\n",
    "        df=spy_testing_table,\n",
    "        column=w_key,\n",
    "        accuracy=spy_testing_table.attrs[f\"{w_key}*\"],\n",
    "        ticker=SPY_TICKER\n",
    "    )\n",
    "    for w_key in w_keys\n",
    "])\n",
    "\n",
    "# Get statistics for all W labels in SONY stock data table.\n",
    "sony_statistics_table: DataFrame = DataFrame([\n",
    "    get_statistics(\n",
    "        df=sony_testing_table,\n",
    "        column=w_key,\n",
    "        accuracy=sony_testing_table.attrs[f\"{w_key}*\"],\n",
    "        ticker=SONY_TICKER\n",
    "    )\n",
    "    for w_key in w_keys\n",
    "])\n",
    "\n",
    "# Build the prediction results statistics table.\n",
    "statistics_table: DataFrame = pd.concat(\n",
    "    [spy_statistics_table, sony_statistics_table]\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:30:14.810594Z",
     "start_time": "2023-03-29T16:30:14.656502Z"
    }
   },
   "outputs": [],
   "source": [
    "show_table(Styler(data=statistics_table, caption=\"Table 3: Prediction Results for W = 1, 2, 3 and ensemble\"), max_rows=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:30:14.811013Z",
     "start_time": "2023-03-29T16:30:14.663209Z"
    }
   },
   "outputs": [],
   "source": [
    "Latex(\n",
    "    r' 8. Discuss your findings.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:30:14.872786Z",
     "start_time": "2023-03-29T16:30:14.669276Z"
    }
   },
   "outputs": [],
   "source": [
    "Latex(\n",
    "    r' Discussion: After viewing an overview of each prediction method, it stands out that W4 has the highest accuracy, but is very close to ensemble. Also, the ensemble recall is very high for both. W3 also has high recall for each and the recall starts to dip going into W4, so that is an interesting observation.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:30:14.873197Z",
     "start_time": "2023-03-29T16:30:14.675835Z"
    }
   },
   "outputs": [],
   "source": [
    "Latex(\n",
    "    rf'$\\textbf{{Question 5: }}$ At the beginning of year $4$, you start with \\$100 dollars and trade for 2 years based upon predicted labels.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:30:14.873497Z",
     "start_time": "2023-03-29T16:30:14.716709Z"
    }
   },
   "outputs": [],
   "source": [
    "Latex(\n",
    "    r' 1. Take your stock. Plot the growth of your amount for 2 years if you trade based on the best $W^*$ and on ensemble. On the same graph, plot the growth of your portfolio for the \"buy-and-hold\" strategy.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:30:15.091926Z",
     "start_time": "2023-03-29T16:30:14.716911Z"
    }
   },
   "outputs": [],
   "source": [
    "initial_investment: float = 100.0\n",
    "\n",
    "# Buy and hold for SONY.\n",
    "buy_and_hold(sony_testing_table, column=BUY_AND_HOLD_KEY)\n",
    "\n",
    "# Buy from the predictions made by the ensemble method.\n",
    "buy_from_prediction(\n",
    "    sony_testing_table, column=ENSEMBLE_ORACLE_KEY, prediction_column=ENSEMBLE_KEY\n",
    ")\n",
    "\n",
    "# Buy from the predictions made by the best W* method.\n",
    "buy_from_prediction(\n",
    "    sony_testing_table, column=W_ORACLE, prediction_column=sony_highest_accuracy[0].replace('*', '')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:30:15.243786Z",
     "start_time": "2023-03-29T16:30:15.017797Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display linechart for SONY.\n",
    "linechart(sony_testing_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:30:15.245343Z",
     "start_time": "2023-03-29T16:30:15.216953Z"
    }
   },
   "outputs": [],
   "source": [
    "Latex(\n",
    "    r' 2. Examine your chart. Any patterns? (e.g any differences in the year 4 and year 5).'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T16:30:15.344732Z",
     "start_time": "2023-03-29T16:30:15.220121Z"
    }
   },
   "outputs": [],
   "source": [
    "Latex(\n",
    "    r'After examining the plot for SONY stock, it is clear that the prediction strategies both had a significant positive impact on the buying strategy compared to the buy and hold strategy. It seems that having a \"W\" value that is higher increases the accuracy and is very close to the ensemble value. I do notice from the graph itself that there is a big dip early on into 2020, and a similar looking dip at around the same time in early 2019, so that could be something to look into as an investor.'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References\n",
    "- https://pandas.pydata.org/docs/user_guide/style.html\n",
    "- https://pandas.pydata.org/docs/user_guide/window.html\n",
    "- https://pandas.pydata.org/pandas-docs/stable/user_guide/style.html#Optimization\n",
    "- https://seaborn.pydata.org/generated/seaborn.lineplot.html\n",
    "- https://matplotlib.org/stable/api/dates_api.html\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html\n",
    "- https://pandas.pydata.org/docs/getting_started/intro_tutorials/03_subset_data.html\n",
    "- https://pandas.pydata.org/docs/getting_started/intro_tutorials/05_add_columns.html\n",
    "- https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
    "- https://ipython.readthedocs.io/en/stable/interactive/magics.html#cell-magics\n",
    "- https://pandas.pydata.org/docs/getting_started/intro_tutorials/06_calculate_statistics.html\n",
    "- https://docs.mathjax.org/en/latest/options/index.html#configuring-mathjax"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assignment2 jupyter kernel",
   "language": "python",
   "name": "assignment2-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
